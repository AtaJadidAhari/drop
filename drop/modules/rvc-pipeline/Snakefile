RVC_WORKDIR = cfg.RVC.renameLocalDir()
RVC_index_input,RVC_graph_file,RVC_index_output = cfg.RVC.getModuleIndexFiles("rvc-pipeline",RVC_WORKDIR)


#########
# Helper Functions
# #######
def getKnownVCFs():
    knownVCFs = ""
    for vcf_file in cfg.config_dict["rnaVariantCalling"]["knownVCFs"]:
        knownVCFs += vcf_file + ";"
    return knownVCFs.strip(";")

def getHaploCallerArgs():
    return cfg.config_dict["rnaVariantCalling"]["hcArgs"]

def getRepeatMask(sortedName=False):
    if sortedName:
        ext = cfg.config_dict["rnaVariantCalling"]["repeat_mask"].strip().split('.')[-1]
        return ".".join(cfg.config_dict["rnaVariantCalling"]["repeat_mask"].strip().split('.')[:-1]) + "_sorted." + ext
    else:
        return cfg.config_dict["rnaVariantCalling"]["repeat_mask"]

def getMinAlt():
    return str(cfg.config_dict["rnaVariantCalling"]["minAlt"])


#################################
#make sure all of the different {datasets} and {samples} are processed. As defined by the sample annotation table RNA_VARIANT_GROUPS
rule rnaVariantCalling:
    priority: 1
    input:  RVC_index_input,
            RVC_graph_file,
            expand(os.path.join(str(cfg.processedDataDir) + "/rnaVariantCalling/{dataset}_alt{minAlt}_done.txt"),
                   dataset = cfg.RVC.groups,minAlt = getMinAlt()),
            expand(os.path.join(
                cfg.processedDataDir,
                "rnaVariantCalling/out/sample_haplocaller", "{sample}",
                "{sample}.genotyped.filtered.basic" + getMinAlt() +".masked.vcf.gz"),
                sample = cfg.RVC.batchIDs)
    output: RVC_index_output
    run:
        if cfg.RVC.run:
            ci(str(RVC_WORKDIR), 'rvc-pipeline')


rule rnaVariantCalling_dependency:
    output: RVC_graph_file
    shell:
        """
        snakemake --rulegraph rnaVariantCalling | \
        sed -ne '/digraph snakemake_dag/,/}}/p' | \
        dot -Tsvg -Grankdir=TB > {output}
        """


#Define the {sample} variable
#create the empty output file of the form: {dataset}_alt{minAlt}_done.txt
rule allVariants:
    priority: 2
    input:
        sample_vcfs = lambda wildcards: expand(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller", "{sample}",
            "{sample}.genotyped.filtered.basic" + getMinAlt() +".masked.vcf.gz"),
            sample = sa.getIDsByGroup(wildcards.dataset,assay = "RVC")),
        batch_vcfs = expand(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            "{batch}_all_samples.genotyped.filtered_clean.vcf.gz"),
            batch = cfg.RVC.groups),
        vcf_counts = lambda wildcards: expand(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller", "{sample}",
            "{sample}_variant_counts.txt"),
            sample = sa.getIDsByGroup(wildcards.dataset,assay = "RVC"))
    output:
        os.path.join(str(cfg.processedDataDir) + "/rnaVariantCalling/{dataset}_alt{minAlt}_done.txt")
    shell:
        """
        touch {output}
        """

rule countVariants:
    priority: 2
    input:
        sample_vcfs = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller", "{sample}",
            "{sample}.genotyped.filtered.basic" + getMinAlt() +".masked.vcf.gz")
    output:
        vcf_counts = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller", "{sample}",
            "{sample}_variant_counts.txt")
    shell:
        """
        total_variants=$(zgrep -vc "#" {input.sample_vcfs})
        pass_variants=$(zgrep -v "#" {input.sample_vcfs} |grep -c -P "PASS|\tMask\t")
        pass_mask_variants=$(zgrep -v "#" {input.sample_vcfs} |grep -wc "PASS")

        hom_total_variants=$(($(zgrep -v "#" {input.sample_vcfs} | grep -wc -F "1/1") +
                              $(zgrep -v "#" {input.sample_vcfs} | grep -wc -F "1|1")))

        hom_pass_variants=$(($(zgrep -v "#" {input.sample_vcfs} | grep -w -F "1/1" |grep -c -P "PASS|\tMask\t" ) +
                             $(zgrep -v "#" {input.sample_vcfs} | grep -w -F "1|1" |grep -c -P "PASS|\tMask\t" )))

        hom_pass_mask_variants=$(($(zgrep -v "#" {input.sample_vcfs} | grep -w -F "1/1" |grep -wc "PASS") +
                             $(zgrep -v "#" {input.sample_vcfs} | grep -w -F "1|1" |grep -wc "PASS")))

        echo "Sample,GT,variants called,\
variants passing filter,\
variants passing filter and repeat mask" > {output.vcf_counts}

        echo "{wildcards.sample},0/1,$(($total_variants - $hom_total_variants)),\
$(($pass_variants - $hom_pass_variants)),\
$(($pass_mask_variants - $hom_pass_mask_variants))" >> {output.vcf_counts}

        echo "{wildcards.sample},1/1,$hom_total_variants,$hom_pass_variants,$hom_pass_mask_variants" >> {output.vcf_counts}
        """

#Use the repeat_mask bedfile to filter/label variants in repeat regions
rule masked_singleVCF_filter:
    priority: 3
    input:
        vcf = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.basic" + getMinAlt() +".vcf.gz"),
        vcf_tabix = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.basic" + getMinAlt() +".vcf.gz.tbi"),
        repeat_mask = getRepeatMask(sortedName = True),
        sample_params = os.path.join(cfg.processedDataDir, "rnaVariantCalling/params/samples" ,
                                    "{sample}_sampleParams.csv")
    output:
        vcf = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.basic" + getMinAlt() +".masked.vcf.gz"),
        tmp_repeat_mask = temp(getRepeatMask(sortedName = True) + "_tmp_{sample}.bed"),
        tmp_repeat_mask_idx = temp(getRepeatMask(sortedName = True) + "_tmp_{sample}.bed.idx")

    params:
        ref = lambda wildcards: cfg.RVC.getGenomePath(wildcards.sample),
    log:
        str(cfg.processedDataDir) + "/logs/sample_haplocaller/" + "{sample}" + "_maskedFilterVariants.log"
    shell:
        """
        vcf_chr_{wildcards.sample}=$(zgrep -v "^#" {input.vcf} | cut -f1 | grep -c "^chr" ||true )
        bed_chr_{wildcards.sample}=$(cat {input.repeat_mask} | cut -f1 | grep -c "^chr" ||true  )

        if [ $vcf_chr_{wildcards.sample} -eq 0  ] && [ $bed_chr_{wildcards.sample} -ne 0 ] #vcf has no chr, bed has chr
        then
            # remove "chr" from the bed file
            sed -e "s/^chr//" {input.repeat_mask} > {output.tmp_repeat_mask}
        elif [ $bed_chr_{wildcards.sample} -eq 0  ] && [ $vcf_chr_{wildcards.sample} -ne 0 ] #vcf has chr, bed has no chr
        then
            # add "chr" to the bed file
            sed -e "s/^/^chr/" {input.repeat_mask} > {output.tmp_repeat_mask}
        else
            cp {input.repeat_mask} {output.tmp_repeat_mask}
        fi

        gatk IndexFeatureFile -I "{input.repeat_mask}_tmp_{wildcards.sample}.bed"
        gatk --java-options "-Djava.io.tmpdir={resources.tmpdir}" VariantFiltration -R {params.ref} \
        -V {input.vcf} --mask {output.tmp_repeat_mask} -O {output.vcf} 2> {log}

        """

rule sortIndexRepeatMask:
    priority: 4
    input:
        repeat_mask = getRepeatMask()
    output:
        sorted_repeat_mask = getRepeatMask(sortedName = True),
        sorted_index = getRepeatMask(sortedName = True) + ".idx"
    shell:
        """
        sort -k1,2 -V {input.repeat_mask} > {output.sorted_repeat_mask}
        gatk IndexFeatureFile -I {output.sorted_repeat_mask}
        """

#Use the minAlt value to filter/label variants that do not have a minimum alternative read support
rule basic_singleVCF_filter:
    priority: 5
    input:
        vcf = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.vcf.gz"),
        vcf_tabix = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.vcf.gz.tbi"),
        bam = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/bam",
            "{sample}",
            "{sample}_Aligned.sortedByCoord.dupMarked.split.bqsr.out.bam")

    output:
        vcf = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.basic" + getMinAlt() +".vcf.gz")),
        vcf_tbi = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.basic" + getMinAlt() +".vcf.gz.tbi"))
    params:
        sample = '{sample}',
        minAlt = getMinAlt(),
        ref = lambda wildcards: cfg.RVC.getGenomePath(wildcards.sample),
    log:
        str(cfg.processedDataDir) + "/logs/sample_haplocaller/" + "{sample}" + "_basicFilterVariants.log"
    shell:
        """
        gatk --java-options "-Djava.io.tmpdir={resources.tmpdir}" VariantFiltration -R {params.ref} \
        -V {input.vcf} --filter-name minAlt --filter-expression "vc.getGenotype('{params.sample}').getAD().1 < {params.minAlt}" \
		-O {output.vcf} 2> {log}
        """


#Use bcftools to split the multi-sample VCF file into a VCF file for the corresponding sample. Normalize the variants to remove artifacts
rule split_multiVCF:
    priority: 6
    input:
        lambda wildcards: os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            cfg.RVC.batchIDs[wildcards.sample] + "_all_samples.genotyped.filtered_clean.vcf.gz"),
    params:
        ref = lambda wildcards: cfg.RVC.getGenomePath(wildcards.sample),
        sampleID = "{sample}",

    output:
        vcf = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.vcf.gz")),

        vcf_tabix = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.vcf.gz.tbi")),
        toDel_split = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.vcf.gz.split")),
        toDel_tmp = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.vcf.gz.tmp"))
    log:
        str(cfg.processedDataDir) + "/logs/sample_haplocaller/{sample}.single_vcf.log"
    shell:
        """
        echo "reading multi-sample vcf into single sample vcf"
        bcftools view -c1 -Oz -s {params.sampleID} -o {output.toDel_tmp} {input}
        echo "split multi-line variants into single lines. Remove those that are artifacts"
        bcftools norm -m-both {output.toDel_tmp} > {output.toDel_split}
        echo "remove redundant variant info AAAG>AC == AAG>C and remove empty variant calls"
        bcftools norm -f {params.ref}  {output.toDel_split} |grep -w -v "*"|grep -w -v "0/0" |bgzip -c > {output.vcf}
        tabix -f -p vcf {output.vcf}
        """


#Use bcftools to left normalize variants. Variants labeled AAAG>AC can be shortened to AAG>C
rule leftNormalVCF:
    priority: 7
    input:
        os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            "{dataset}" + "_all_samples.genotyped.filtered.split.vcf.gz")
    output:
        os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            "{dataset}_all_samples.genotyped.filtered_clean.vcf.gz")
    params:
        ref = lambda wildcards: cfg.RVC.getGenomePath(wildcards.dataset)
    shell:
        """
        bcftools norm -f {params.ref} {input} | bgzip -c > {output}
        tabix -f -p vcf {output}
         """


#Use bcftools to split VCF with multiple variants on a single line into a VCF with a single variant per line. G>A,C into 2 lines G>A and G>C
rule splitVCF:
    priority: 8
    input:
        ancient(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            "{dataset}_all_samples.genotyped.filtered.vcf.gz"))
    output:
        split_vcf = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            "{dataset}" + "_all_samples.genotyped.filtered.split.vcf.gz"
            )),
        toDel = temp(os.path.join(
                cfg.processedDataDir,
                "rnaVariantCalling/tmp/",
                "{dataset}" + "_DELETE_ME"))
    shell:
        """
        bcftools norm -m-both {input} > {output.toDel}
        grep -v -w "*" {output.toDel} |bgzip -c > {output.split_vcf}
        """


#Use GATK to filter variants based on the quality scores and variant frequency based on the GATK-best practices
rule filterVCF:
    priority: 9
    input:
        os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/all_samples_haplocaller",
        "{dataset}_all_samples.genotyped.vcf.gz")

    output:
        filt_vcf = temp(os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/all_samples_haplocaller",
        "{dataset}_all_samples.genotyped.filtered.vcf.gz"
        )),
        filt_vcf_tbi = temp(os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/all_samples_haplocaller",
        "{dataset}_all_samples.genotyped.filtered.vcf.gz.tbi"))
    params:
        ref = lambda wildcards: cfg.RVC.getGenomePath(wildcards.dataset),
    log:
        str(cfg.processedDataDir) + "/logs/all_haplocaller/{dataset}_filterVariants.log"
    shell:
        """
        gatk --java-options "-Djava.io.tmpdir={resources.tmpdir}" VariantFiltration -R {params.ref} -V {input} \
        -window 35 -cluster 3 --filter-name FS --filter-expression "FS > 30.0" \
        --filter-name QD --filter-expression "QD < 2.0" -O {output.filt_vcf} 2> {log}
        """


#Using GATK GenotypeGVCFs to make the variant calls from the combined g.vcf files
rule genotypeGVCFs:
    priority: 10
    input:
        gvcf = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            "{dataset}_all_samples.g.vcf.gz"),

        gvcf_tbi = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            "{dataset}_all_samples.g.vcf.gz.tbi"),

        batch_params = os.path.join(cfg.processedDataDir, "rnaVariantCalling/params/batches" ,
                                    "{dataset}_batchParams.csv")
    output:
        vcf = temp(os.path.join( cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            "{dataset}_all_samples.genotyped.vcf.gz")),
        tbi = temp(os.path.join( cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            "{dataset}_all_samples.genotyped.vcf.gz.tbi"))
    params:
        ref = lambda wildcards: cfg.RVC.getGenomePath(wildcards.dataset),
    log:
        str(cfg.processedDataDir) + "/logs/all_haplocaller/{dataset}_genotypeGVCFs.log"
    shell:
        """
        gatk --java-options "-Djava.io.tmpdir={resources.tmpdir}" GenotypeGVCFs -R {params.ref} \
        --variant {input.gvcf} -O {output.vcf} 2> {log}
        """


#Using GATK combine the vcfs from each sample within a {dataset} into a multi-sample vcf file to improve genotyping and variant calls
rule combineGVCFs:
    priority: 11
    input:
        gvcfs = lambda wildcards: expand(
            os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.g.vcf.gz"
            ), sample = sa.getIDsByGroup(wildcards.dataset,assay = "RVC"))
    output:
        gvcf = os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/all_samples_haplocaller",
        "{dataset}_all_samples.g.vcf.gz"
        ),

        gvcf_tbi = os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/all_samples_haplocaller",
        "{dataset}_all_samples.g.vcf.gz.tbi")
    params:
        ref = lambda wildcards: cfg.RVC.getGenomePath(wildcards.dataset),
        variant_list = lambda wildcards: [f"--variant {gvcf}" for gvcf in expand(
            os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.g.vcf.gz"
            ), sample = sa.getIDsByGroup(wildcards.dataset,assay = "RVC"))]
    log:
        str(cfg.processedDataDir) + "/logs/all_haplocaller/{dataset}_combineGVCF.log"
    shell:
        """
        gatk --java-options "-Djava.io.tmpdir={resources.tmpdir}" CombineGVCFs -R {params.ref} \
         {params.variant_list} -O {output.gvcf} 2> {log}
        """


#Using GATK HaplotypeCaller take the cleaned and recalibrated BAM file as input for the variant calling.
rule haplotypeCaller:
    priority: 12
    input:
        bam = os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/bam",
        "{sample}",
        "{sample}_Aligned.sortedByCoord.dupMarked.split.bqsr.out.bam"),
        bai = os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/bam",
        "{sample}",
        "{sample}_Aligned.sortedByCoord.dupMarked.split.bqsr.out.bai")
    output:
        os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/sample_haplocaller",
        "{sample}",
        "{sample}.g.vcf.gz")
    params:
        ref = lambda wildcards: cfg.RVC.getGenomePath(wildcards.sample),
        hcArgs = getHaploCallerArgs(),
    log:
        str(cfg.processedDataDir) + "/logs/all_haplocaller/{sample}.log"
    shell:
        """
        gatk --java-options "-Djava.io.tmpdir={resources.tmpdir}" HaplotypeCaller -R {params.ref} -I {input.bam} \
        --dont-use-soft-clipped-bases -stand-call-conf 20.0 \
        --output-mode EMIT_ALL_CONFIDENT_SITES \
        -ERC GVCF {params.hcArgs} -O {output} 2> {log}
        """


#Using GATK ApplyBQSR takes the frequency table and confidence scores generated by BQSR and recalculates the BAM quality scores
rule applyBQSR:
    priority: 13
    input:
        bam = os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/bam",
        "{sample}",
        "{sample}_Aligned.sortedByCoord.dupMarked.split.out.bam"),
        bai = os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/bam",
        "{sample}",
        "{sample}_Aligned.sortedByCoord.dupMarked.split.out.bai"),
        table = os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/bqsr/{sample}_recal.table")
    output:
        bam = temp(os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/bam",
        "{sample}",
        "{sample}_Aligned.sortedByCoord.dupMarked.split.bqsr.out.bam")),
        bai = temp(os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/bam",
        "{sample}",
        "{sample}_Aligned.sortedByCoord.dupMarked.split.bqsr.out.bai"))
    params:
        ref = lambda wildcards: cfg.RVC.getGenomePath(wildcards.sample),
    log:
        str(cfg.processedDataDir) + "/logs/applyBQSR/{sample}.log"
    shell:
        """
        gatk --java-options "-Djava.io.tmpdir={resources.tmpdir}" ApplyBQSR  \
        -R {params.ref} -I {input.bam} --bqsr-recal-file {input.table} \
        --add-output-sam-program-record --use-original-qualities -O {output.bam} 2> {log}
        """


#Using GATK BaseRecalibrator (BQSR) use the known sites (dbSNP + others) to improve read scoring
rule bqsr:
    priority: 14
    input:
        bam = os.path.join(
                cfg.processedDataDir,
                "rnaVariantCalling/out/bam",
                "{sample}",
                "{sample}_Aligned.sortedByCoord.dupMarked.split.out.bam"),
        bai = os.path.join(
                cfg.processedDataDir,
                "rnaVariantCalling/out/bam",
                "{sample}",
                "{sample}_Aligned.sortedByCoord.dupMarked.split.out.bai"),
        script = str(RVC_WORKDIR) + "/GATK_BASH/bqsr.sh"
    output:
        bqsr_table = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/bqsr",
            "{sample}_recal.table")
    params:
        ref = lambda wildcards: cfg.RVC.getGenomePath(wildcards.sample),
        known_sites = getKnownVCFs(),
        ucsc2ncbi = str(cfg.MAE.renameLocalDir())  + "/resource/chr_UCSC_NCBI.txt",
        ncbi2ucsc = str(cfg.MAE.renameLocalDir())  + "/resource/chr_NCBI_UCSC.txt",
    log:
        str(cfg.processedDataDir) + "/logs/bqsr/{sample}.log"
    shell:
        """
        {input.script} {input.bam} {input.bai} \
        {params.ref} "{params.known_sites}" {params.ucsc2ncbi} {params.ncbi2ucsc} \
        {log} {output.bqsr_table}
        """


#Using GATK splitNCigarReads make use of the RNA splicing characteristic by mapping reads with large gaps to the reference. Split the RNAseq reads into subsections that will have better local alignments
rule splitNcigar:
    priority: 15
    input:
        bam = os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/bam",
        "{sample}",
        "{sample}_Aligned.sortedByCoord.dupMarked.FAorder.out.bam"),
    output:
        bam = temp(os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/bam",
        "{sample}",
        "{sample}_Aligned.sortedByCoord.dupMarked.split.out.bam")),
        bai = temp(os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/bam",
        "{sample}",
        "{sample}_Aligned.sortedByCoord.dupMarked.split.out.bai"))
    params:
        ref = lambda wildcards: cfg.RVC.getGenomePath(wildcards.sample),
    log:
        str(cfg.processedDataDir) + "/logs/splitNcigar/{sample}.log"
    shell:
        """
        gatk --java-options "-Djava.io.tmpdir={resources.tmpdir}" SplitNCigarReads \
        -R {params.ref} -I {input.bam} -fixNDN \
        -O {output.bam} 2> {log}
        #-RMQT 60 -U ALLOW_N_CIGAR_READS --allow_potentially_misencoded_quality_scores 2> {log}
        """

# Using picard ReorderSam the bam files so that they match the reference genome order.
rule reorderBAM:
    priority: 16
    input:
        bam = os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/bam",
        "{sample}",
        "{sample}_Aligned.sortedByCoord.dupMarked.out.bam"),
    output:
        bam = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/bam",
            "{sample}",
            "{sample}_Aligned.sortedByCoord.dupMarked.FAorder.out.bam"
            )),
        bai = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/bam",
            "{sample}",
            "{sample}_Aligned.sortedByCoord.dupMarked.FAorder.out.bam.bai"))
    params:
        tmp_bai = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/bam",
            "{sample}",
            "{sample}_Aligned.sortedByCoord.dupMarked.FAorder.out.bai"),
        ref = lambda wildcards: cfg.RVC.getGenomePath(wildcards.sample),
        ref_dict = lambda wildcards: cfg.RVC.getGenomePath(wildcards.sample).rsplit(".",1)[0] + ".dict"
    shell:
        """
        echo "Create Sequence Dictionary"
        if [ ! -f "{params.ref_dict}" ]; then
            gatk CreateSequenceDictionary -R {params.ref}
        fi
        echo "ReorderSam"
        gatk ReorderSam -I {input.bam} -O {output.bam} --SEQUENCE_DICTIONARY {params.ref_dict} -S true --CREATE_INDEX true # remove me for gatk4.0.4.0
        echo "mv {params.tmp_bai} {output.bai}"
        mv {params.tmp_bai} {output.bai}
        """

#Using GATK markDuplicates attempt to identify reads that are technical duplicates of biological reads. Attempts to eliminate noise introduced by library prep
rule markDuplicates:
    priority: 17
    input:
        bam = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/bam",
            "{sample}",
            "{sample}_Aligned.sortedByCoord.out.bam"),
        bai = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/bam",
            "{sample}",
            "{sample}_Aligned.sortedByCoord.out.bam.bai")
    output:
        bam = temp(os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/bam",
        "{sample}",
        "{sample}_Aligned.sortedByCoord.dupMarked.out.bam")),
        bai = temp(os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/bam",
        "{sample}",
        "{sample}_Aligned.sortedByCoord.dupMarked.out.bai"))
    params:
        metrics = os.path.join( cfg.processedDataDir, "rnaVariantCalling/out/picard-tools-marked-dup-metrics.txt"),
    log:
        str(cfg.processedDataDir) + "/logs/markDuplicates/{sample}.log"
    shell:
        """
        gatk MarkDuplicates -I {input.bam} -O {output.bam} \
        -M {params.metrics} --CREATE_INDEX true \
        --TMP_DIR "{resources.tmpdir}" \
        --VALIDATION_STRINGENCY SILENT 2> {log}
        """


#Using samtools sort the reads based on their chromosomal coordinates
rule sortBam:
    priority: 18
    input:
        bam = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/bam",
            "{sample}",
            "{sample}_dropHeader.bam"),
        bai = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/bam",
            "{sample}",
            "{sample}_dropHeader.bam.bai")
    output:
        bam = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/bam",
            "{sample}",
            "{sample}_Aligned.sortedByCoord.out.bam")),
        bai = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/bam",
            "{sample}",
            "{sample}_Aligned.sortedByCoord.out.bam.bai"))
    log:
        str(cfg.processedDataDir) + "/logs/sortBam/{sample}.log"

    shell:
        """
        samtools sort {input.bam} -O BAM -o {output.bam} &> {log}
        samtools index -b {output.bam}
        """


rule changeHeader:
    priority: 19
    input:
        bam = str(cfg.processedDataDir) + "/rnaVariantCalling/bam_file_links/{sample}.bam",
        bai = str(cfg.processedDataDir) + "/rnaVariantCalling/bam_file_links/{sample}.bam.bai",
        script = str(RVC_WORKDIR) + "/GATK_BASH/changeHeader.sh"
    output:
        bam = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/bam",
            "{sample}",
            "{sample}_dropHeader.bam")),
        bai = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/bam",
            "{sample}",
            "{sample}_dropHeader.bam.bai")),
        newHeader = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/bam",
            "{sample}",
            "{sample}_newDropHeader.txt")
    params:
        sample="{sample}"
    log:
        str(cfg.processedDataDir) + "/logs/changeHeader/{sample}.log"
    shell:
        """
        {input.script} {input.bam} {input.bai} {params.sample} {log} \
        {output.bam} {output.bai} {output.newHeader}
        """



#Using samtools index the bam files if they are not already indexed, and create a soft link to the working directory for easier access
rule indexReads:
    priority: 20
    input:
        bam = lambda wildcards: sa.getFilePath(wildcards.sample, "RNA_BAM_FILE"),
        script = str(RVC_WORKDIR) + "/GATK_BASH/indexReads.sh"
    output:
        bam = str(cfg.processedDataDir) + "/rnaVariantCalling/bam_file_links/{sample}.bam",
        bai = str(cfg.processedDataDir) + "/rnaVariantCalling/bam_file_links/{sample}.bam.bai"
    log:
        str(cfg.processedDataDir) + "/logs/indexReads/{sample}.log"
    shell:
        """
        {input.script} {input.bam} {log} {output.bam} {output.bai}
        """

# MUST UNCOMMENT indexReads
#rule readGroups:
#    input:
#        lambda wildcards: sa.getFilePath(wildcards.sample, "RNA_BAM_FILE")
#    output:
#        bam = str(cfg.processedDataDir) + "/rnaVariantCalling/bam_file_links/{sample}.bam",
#        bai = str(cfg.processedDataDir) + "/rnaVariantCalling/bam_file_links/{sample}.bam.bai"
#    params:
#        sample = "{sample}" ,
#        tmp_bai = str(cfg.processedDataDir) + "/rnaVariantCalling/bam_file_links/{sample}.bai"
#    log:
#        str(cfg.processedDataDir) + "/logs/readGroups/{sample}.log"
#    shell:
#        """
#        picard AddOrReplaceReadGroups I={input} O={output.bam} SORT_ORDER=coordinate \
#            RGID=1 RGLB="BONN" RGPL=unknown RGPU=unit1 RGSM={params.sample} CREATE_INDEX=True &> {log}
#        mv {params.tmp_bai} {output.bai}
#        #"""
